# Benchmark

此目录用于对不同模型生成的武侠风格代码注释进行评测和分析。

## 调用方式

```bash
# 运行评估
npm run benchmark

# 分析排名结果
npm run analyze
```

## 目录结构

```
benchmark/
├── README.md           # 说明文档
├── index.js            # 评测入口
├── evaluate.js         # 评估器：根据“评估纬度”评估模型
├── benchmark.js         # 基准测试：基准测试的执行流程
├── analyze.js          # 分析器：生成模型排名报告
├── testsuit/          # 测试相关数据
│   └── testModels      # 符合“合规、隐私要求的大模型”列表
│   └── testcase        # 测试用例
├── report/             # 原始评测数据
│   └── *.json          # 模型评估报告
└── analysis_*.json     # 模型排名报告
```

## 评估纬度

每个模型会对同一测试用例进行多次评测，以确保结果的可靠性。评估分为以下几个维度：

1. 内容质量 (35%)

   - 武侠关键词率
   - 注释覆盖率
   - 风格一致性
   - 可读性
   - 创意性

2. 结构稳定性 (30%)

   评估模型生成结构化输出的能力，基于多次测试中格式正确的比例计算

3. 时间消耗 (20%)

   评估模型生成注释的耗时

4. 成本消耗 (15%)

   评估模型生成注释的成本

## 评分标准

### 内容质量评分 (0-10 分)

1. 武侠关键词率

   - 评估生成的注释中武侠术语的使用情况
   - 关键词覆盖度和使用准确性

2. 注释覆盖率

   - 评估代码的关键部分是否都有对应注释
   - 注释的完整性和全面性

3. 风格一致性

   - 评估注释风格是否统一
   - 是否始终保持武侠风格

4. 可读性

   - 评估注释是否清晰易懂
   - 是否准确传达代码含义

5. 创意性
   - 评估比喻是否新颖有趣
   - 故事性和趣味性

### 结构稳定性评分

评估模型生成结构化输出的能力，基于多次测试中格式正确的比例计算：

- 所有输出均正确：10 分
- 90%以上正确：8 分
- 80-90%正确：6 分
- 70-80%正确：4 分
- 60-70%正确：2 分
- 低于 60%：0 分

### 时间效率评分

基于生成耗时计算：

- 3 秒内：10 分
- 3-30 秒：线性递减
- 超过 30 秒：0 分

### 成本效率评分

基于 token 消耗计算：

- 0.025 元内：10 分
- 0.025-0.25 元：线性递减
- 超过 0.25 元：0 分

## 分析报告

分析报告包含以下内容：

- 总体统计信息
- 各模型详细评分
- 样本数据统计
- 性能排名
