# Benchmark

此目录用于对不同模型生成的武侠风格代码注释进行评测和分析。

## 调用方式

```bash
# 运行评测
npm run benchmark

# 分析结果
npm run analyze
```

## 目录结构

```
benchmark/
├── README.md           # 说明文档
├── index.js           # 评测入口
├── evaluate.js        # 评估器实现
├── analyze.js         # 用于生成结果报告
├── testcases/        # 测试相关数据
│   └── quicksort.js   # 快速排序测试用例
├── models/           # 模型配置
├── report/           # 原始评测数据
│   └── *.json        # 每次评测的结果
└── analysis_*.json   # 分析报告
```

## 评估方式

每个模型会对同一测试用例进行多次评测，以确保结果的可靠性。评估分为以下几个维度：

1. 内容质量 (35%)

   - 武侠关键词率
   - 注释覆盖率
   - 风格一致性
   - 可读性
   - 创意性

2. 结构稳定性 (30%)

   - 100% 稳定：10 分
   - 90-99% 稳定：8 分
   - 80-90% 稳定：6 分
   - 70-80% 稳定：4 分
   - 60-70% 稳定：2 分
   - <60% 稳定：0 分

3. 时间消耗 (20%)

   - 3 秒内：满分
   - 3-30 秒：线性扣分
   - > 30 秒：0 分

4. 成本消耗 (15%)
   - 每 0.025 元扣 1 分
   - 0.25 元及以上：0 分

## 评分标准

### 内容质量评分 (0-10 分)

1. 武侠关键词率

   - 评估生成的注释中武侠术语的使用情况
   - 关键词覆盖度和使用准确性

2. 注释覆盖率

   - 评估代码的关键部分是否都有对应注释
   - 注释的完整性和全面性

3. 风格一致性

   - 评估注释风格是否统一
   - 是否始终保持武侠风格

4. 可读性

   - 评估注释是否清晰易懂
   - 是否准确传达代码含义

5. 创意性
   - 评估比喻是否新颖有趣
   - 故事性和趣味性

### 结构稳定性评分

评估模型生成结构化输出的能力，基于多次测试中格式正确的比例计算：

- 所有输出均正确：10 分
- 90%以上正确：8 分
- 80-90%正确：6 分
- 70-80%正确：4 分
- 60-70%正确：2 分
- 低于 60%：0 分

### 时间效率评分

基于生成耗时计算：

- 3 秒内：10 分
- 3-30 秒：线性递减
- 超过 30 秒：0 分

### 成本效率评分

基于 token 消耗计算：

- 0.025 元内：10 分
- 0.025-0.25 元：线性递减
- 超过 0.25 元：0 分

## 分析报告

分析报告包含以下内容：

- 总体统计信息
- 各模型详细评分
- 样本数据统计
- 性能排名
